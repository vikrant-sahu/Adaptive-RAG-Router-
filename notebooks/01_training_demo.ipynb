{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27c3d709",
   "metadata": {},
   "source": [
    "# Adaptive RAG Router - Training Demo\n",
    "\n",
    "This notebook demonstrates training the **Adaptive RAG Router** on CLINC150 dataset.\n",
    "\n",
    "Works on both GitHub and Kaggle!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf05822",
   "metadata": {
    "tags": [
     "installation"
    ]
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Install package if running in Kaggle/Colab\n",
    "IS_KAGGLE = 'KAGGLE_KERNEL_RUN_TYPE' in os.environ\n",
    "IS_COLAB = 'COLAB_GPU' in os.environ\n",
    "\n",
    "if IS_KAGGLE or IS_COLAB:\n",
    "    print(f\"üöÄ Running on {'Kaggle' if IS_KAGGLE else 'Colab'}\")\n",
    "    \n",
    "    # Install with no cache to save disk space\n",
    "    !pip install -q --no-cache-dir transformers datasets peft accelerate torch \\\n",
    "                    scikit-learn matplotlib seaborn tqdm\n",
    "    \n",
    "    # Clear pip cache\n",
    "    !rm -rf ~/.cache/pip\n",
    "    \n",
    "    print(\"‚úÖ Dependencies installed\")\n",
    "\n",
    "# For local development, the package would be installed via setup.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488e9e7d",
   "metadata": {
    "tags": [
     "imports"
    ]
   },
   "outputs": [],
   "source": "import torch\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom adaptive_rag_router import (\n    CLINC150DataLoader,\n    AdaptiveRAGRouter,\n    create_router_model,\n    ModelTrainer\n)\n\nprint(\"üöÄ Adaptive RAG Router - Training Demo\")\nprint(f\"PyTorch: {torch.__version__}\")\nprint(f\"CUDA: {torch.cuda.is_available()}\")\n\n# ================================\n# CONFIGURATION PARAMETERS\n# ================================\n# Modify these parameters as needed\n\n# Training Configuration\nNUM_EPOCHS = 5  # Number of training epochs\nBATCH_SIZE = 16  # Batch size for training\nMODEL_TYPE = \"distilbert\"  # Model type: 'distilbert', 'roberta', or 'deberta'\n\n# Data Split Configuration\nUSE_CUSTOM_SPLIT = True  # Use 70/30 split? (True = 70% train+val, 30% test; False = use default splits)\nTRAIN_VAL_RATIO = 0.7  # Ratio for train+val when using custom split\n\n# Model Saving\nMODEL_SAVE_PATH = \"./trained_models/adaptive_router\"  # Path to save the trained model\n\nprint(f\"\\n‚öôÔ∏è Configuration:\")\nprint(f\"  - Epochs: {NUM_EPOCHS}\")\nprint(f\"  - Batch Size: {BATCH_SIZE}\")\nprint(f\"  - Model Type: {MODEL_TYPE}\")\nprint(f\"  - Custom Split: {USE_CUSTOM_SPLIT}\")\nif USE_CUSTOM_SPLIT:\n    print(f\"  - Train+Val Ratio: {TRAIN_VAL_RATIO*100:.0f}% (Test: {(1-TRAIN_VAL_RATIO)*100:.0f}%)\")\nprint(f\"  - Save Path: {MODEL_SAVE_PATH}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86d97a7",
   "metadata": {
    "tags": [
     "quick-demo"
    ]
   },
   "outputs": [],
   "source": [
    "print(\"üéØ Quick Demo - Model Prediction\")\n",
    "\n",
    "# Initialize a pretrained model\n",
    "model = create_router_model(\"distilbert\")\n",
    "\n",
    "# Test predictions\n",
    "test_queries = [\n",
    "    \"What's my account balance?\",\n",
    "    \"I need to transfer money between accounts\",\n",
    "    \"What's the weather like today?\",\n",
    "    \"Can you help me with my credit card application?\",\n",
    "]\n",
    "\n",
    "results = model.predict(test_queries)\n",
    "\n",
    "print(\"\\nüìä Prediction Results:\")\n",
    "for i, query in enumerate(test_queries):\n",
    "    domain = results[\"domains\"][i]\n",
    "    confidence = results[\"confidences\"][i]\n",
    "    print(f\" '{query}' ‚Üí {domain} ({confidence:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc8d249",
   "metadata": {
    "tags": [
     "data-exploration"
    ]
   },
   "outputs": [],
   "source": "print(\"\\nüìà Data Exploration\")\n\ndata_loader = CLINC150DataLoader()\n\n# Show data split information\nif USE_CUSTOM_SPLIT:\n    print(f\"Using custom {TRAIN_VAL_RATIO*100:.0f}/{(1-TRAIN_VAL_RATIO)*100:.0f} train+val/test split\")\n    train_loader, val_loader, test_loader = data_loader.get_custom_split_loaders(\n        batch_size=8,\n        train_val_ratio=TRAIN_VAL_RATIO\n    )\nelse:\n    print(\"Using default dataset splits\")\n    train_loader, val_loader, test_loader = data_loader.get_data_loaders(batch_size=8)\n\nprint(f\"\\nData Split:\")\nprint(f\"  - Training batches: {len(train_loader)} (samples: {len(train_loader.dataset)})\")\nprint(f\"  - Validation batches: {len(val_loader)} (samples: {len(val_loader.dataset)})\")\nprint(f\"  - Test batches: {len(test_loader)} (samples: {len(test_loader.dataset)})\")\n\ntotal_samples = len(train_loader.dataset) + len(val_loader.dataset) + len(test_loader.dataset)\nprint(f\"  - Total samples: {total_samples}\")\n\n# Show domain distribution\ndataset = data_loader.load_dataset(\"train\", sample_size=1000)\ndomains = [data_loader.extract_domain_from_intent(item['intent']) for item in dataset]\n\nfrom collections import Counter\ndomain_counts = Counter(domains)\n\nplt.figure(figsize=(10, 6))\nplt.bar(domain_counts.keys(), domain_counts.values())\nplt.title('Domain Distribution in CLINC150 (Sample)')\nplt.xlabel('Domain')\nplt.ylabel('Count')\nplt.xticks(rotation=45, ha='right')\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30890ee2",
   "metadata": {
    "tags": [
     "training"
    ]
   },
   "outputs": [],
   "source": "print(\"\\nüéì Model Training\")\n\ntrainer = ModelTrainer()\n\n# Prepare training configuration\ntraining_config = {\n    \"num_epochs\": NUM_EPOCHS,\n    \"per_device_train_batch_size\": BATCH_SIZE,\n}\n\n# For cloud environments, adjust epochs but use full dataset with 70/30 split\nif 'KAGGLE_KERNEL_RUN_TYPE' in os.environ or 'COLAB_GPU' in os.environ:\n    print(\"üèÉ Running training on cloud (70% of full dataset for train+val)...\")\n    # Use full dataset with 70/30 split (no sample_size limitation)\n    results = trainer.train_model(\n        model_type=MODEL_TYPE,\n        training_config={\"num_epochs\": 3, \"per_device_train_batch_size\": 16},\n        sample_size=None,  # Use full dataset\n        use_custom_split=True,  # Use 70/30 split\n        train_val_ratio=0.7,  # 70% for train+val, 30% for test\n        save_path=MODEL_SAVE_PATH\n    )\nelse:\n    print(\"üîß Running full training with custom split...\")\n    results = trainer.train_model(\n        model_type=MODEL_TYPE,\n        training_config=training_config,\n        use_custom_split=USE_CUSTOM_SPLIT,\n        train_val_ratio=TRAIN_VAL_RATIO,\n        save_path=MODEL_SAVE_PATH\n    )\n\nprint(f\"\\n‚úÖ Training completed!\")\nprint(f\"üìä Results:\")\nprint(f\"  - Test Accuracy: {results['test_accuracy']:.4f}\")\nprint(f\"  - Test Precision: {results['test_precision']:.4f}\")\nprint(f\"  - Test Recall: {results['test_recall']:.4f}\")\nprint(f\"  - Test F1 Score: {results['test_f1']:.4f}\")\nprint(f\"  - Model saved to: {results['output_dir']}\")"
  },
  {
   "cell_type": "code",
   "id": "vetq8o8ovmb",
   "source": "print(\"\\nüìä Detailed Performance Metrics\")\n\n# Display per-class metrics\nprint(\"\\nPer-Domain Performance:\")\nprint(\"=\" * 70)\nper_class = results['per_class_metrics']\n\n# Create a DataFrame for better visualization\nmetrics_data = []\nfor domain, metrics in per_class.items():\n    metrics_data.append({\n        'Domain': domain,\n        'Precision': metrics['precision'],\n        'Recall': metrics['recall'],\n        'F1-Score': metrics['f1']\n    })\n\nmetrics_df = pd.DataFrame(metrics_data)\nmetrics_df = metrics_df.sort_values('F1-Score', ascending=False)\nprint(metrics_df.to_string(index=False))\n\n# Visualize per-class F1 scores\nplt.figure(figsize=(12, 6))\nplt.barh(metrics_df['Domain'], metrics_df['F1-Score'])\nplt.xlabel('F1 Score')\nplt.title('F1 Score by Domain')\nplt.tight_layout()\nplt.show()\n\n# Visualize confusion matrix\nprint(\"\\n\\nConfusion Matrix:\")\ncm = results['confusion_matrix']\ndomain_names = list(per_class.keys())\n\nplt.figure(figsize=(12, 10))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n            xticklabels=domain_names, yticklabels=domain_names)\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Confusion Matrix - Test Set Performance')\nplt.xticks(rotation=45, ha='right')\nplt.yticks(rotation=0)\nplt.tight_layout()\nplt.show()\n\nprint(f\"\\n‚úÖ Detailed metrics saved to: {results['output_dir']}/training_results.json\")\nprint(f\"‚úÖ Classification report saved to: {results['output_dir']}/classification_report.txt\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed800384",
   "metadata": {
    "tags": [
     "evaluation"
    ]
   },
   "outputs": [],
   "source": [
    "print(\"\\nüìä Model Evaluation\")\n",
    "\n",
    "# Load the trained model\n",
    "trained_model = AdaptiveRAGRouter()\n",
    "trained_model.load(results['output_dir'])\n",
    "\n",
    "# Test on sample queries\n",
    "test_queries = [\n",
    "    \"What's my current balance?\",\n",
    "    \"I want to pay my credit card bill\",\n",
    "    \"What's the weather forecast?\",\n",
    "    \"Book a flight to London\",\n",
    "    \"Reset my password please\"\n",
    "]\n",
    "\n",
    "predictions = trained_model.predict(test_queries)\n",
    "\n",
    "print(\"Model Predictions on Test Queries:\")\n",
    "for i, query in enumerate(test_queries):\n",
    "    print(f\" {query:<40} ‚Üí {predictions['domains'][i]:<20} (conf: {predictions['confidences'][i]:.3f})\")\n",
    "\n",
    "print(\"\\nüéâ Demo completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}